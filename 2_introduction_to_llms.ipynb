{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65c9fdf3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "<h1 style=\"text-align:center;font-weight:normal;font-size:75pt;\">Introducción a LLMs</h1>\n",
    "\n",
    "<div style=\"text-align:center;\">\n",
    "    <div style=\"display:inline-block;margin-right:20px;\">\n",
    "        <img src=\"./img/logo.png\" style=\"height:10em;width:auto;\"/>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7f3997",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# ¿Qué es un LLM?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d1ca59",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### ¿Cómo continúa esta frase?\n",
    "\n",
    "<h2 style=\"text-align:center;font-weight:normal;font-size:3em;\">You ...</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5a5c6b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "<h2 style=\"text-align:center;font-weight:normal;font-size:3em;\">You shall ...</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71da59e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "<h2 style=\"text-align:center;font-weight:normal;font-size:3em;\">You shall not ...</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2910e985",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "<div style=\"text-align:center;\">\n",
    "    <h2 style=\"font-weight:normal;font-size:3em;\">You shall not pass!</h2>\n",
    "    <div style=\"display:inline-block;margin-top:10px;\">\n",
    "        <img src=\"./img/gandalf.gif\" style=\"height:15em;width:auto;\"/>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8b67ee60-29d5-4ded-b4bf-8e7e37ad6091",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## ¿Cómo funcionan los LLMs y qué tipos existen?\n",
    "\n",
    "- Los modelos de lenguaje (o Language Models) son modelos que buscan emular el lenguaje humano.\n",
    "- Dado un contexto de entrada (e.g., una lista de palabras) modelan la salida (e.g., la palabra siguiente a la lista de palabras del contexto).\n",
    "    - No todos los modelos de lenguaje son LLMs y algunos ni siquiera son probabilísticos (e.g., las gramátias de Chomsky).\n",
    "- Los modelos masivos de lenguajes (Large Language Models o LLMs) son modelos probabilísticos de aprendizaje automático entrenados con una gran cantidad de datos y de parámetros:\n",
    "    - Suelen entrenarse con corpus del orden de $10^{10}$ tokens.\n",
    "    - Suelen tener de $10^8$ o $10^9$ parámetros en adelante.\n",
    "    - El término se asocia generalmente a aquellos modelos basados en la arquitectura neuronal del Transformer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc710ea",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### ¿Qué es un \"Transformer\"?\n",
    "\n",
    "- Es una arquitectura de red neuronal que se presentó en el paper [\"Attention is All You Need\"](https://arxiv.org/abs/1706.03762).\n",
    "- Existen variantes, de acuerdo a que parte de la arquitectura usan:\n",
    "    - Los modelos de traducción de secuencia a secuencia (e.g. el [Transformer](https://arxiv.org/abs/1706.03762) o el [T5](https://arxiv.org/abs/1910.10683)). Tienen codificador y decodificador. Sirven para tareas de transformación (e.g. traducción).\n",
    "    - Los modelos basados en el codificador (e.g. [BERT](https://arxiv.org/abs/1810.04805)). Sirven para buscar representaciones vectoriales (embeddings) del texto.\n",
    "    - Los modelos basados en el decodificador, o autoregresivos (e.g., [GPT](https://arxiv.org/abs/2005.14165)). Sirven para generación de texto.\n",
    "- La idea del transformer es \"definir\" una palabra de acuerdo a la relación que tiene con las palabras de su vecindario, en una operación de multiplicación matricial con pesos.\n",
    "    - Para una explicación sencilla pero más detallada sugiero los posts de la serie \"The Illustrated...\" de [Jay Alammar](http://jalammar.github.io/):\n",
    "        - [The Illustrated Transformer](http://jalammar.github.io/illustrated-transformer/)\n",
    "        - [The Illustrated BERT](http://jalammar.github.io/illustrated-bert/)\n",
    "        - [The Illustrated GPT-2](http://jalammar.github.io/illustrated-gpt2/) / [How GPT-3 Works](http://jalammar.github.io/how-gpt3-works-visualizations-animations/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74f6b22-f566-4980-85f5-044f983866be",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Arquitecturas de Transformers\n",
    "\n",
    "<div style=\"text-align:center;\">\n",
    "    <div style=\"display:inline-block;margin-right:20px;\">\n",
    "        <img src=\"./img/transformer.jpg\" style=\"height:40em;width:auto;\"/>\n",
    "    </div>\n",
    "    <h6 style=\"font-style:normal;font-size:1em;margin:5px;\">\n",
    "        Source: <a href=\"https://huggingface.co/learn/agents-course/en/unit1/what-are-llms\" style=\"color:royalblue;\" target=\"_blank\">Hugging Face Agents Course - What are LLMs?</a>\n",
    "    </h6>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f421d8-dd14-4651-a47a-625f563bda3b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## ¿Cómo se entrena un LLM?\n",
    "\n",
    "<div style=\"text-align:center;\">\n",
    "    <div style=\"display:inline-block;margin-right:20px;\">\n",
    "        <img src=\"./img/transformers-training.jpg\" style=\"height:40em;width:auto;\"/>\n",
    "    </div>\n",
    "    <h6 style=\"font-style:normal;font-size:1em;margin:5px;\">\n",
    "        Source: <a href=\"https://cameronrwolfe.substack.com/p/understanding-and-using-supervised\" style=\"color:royalblue;\" target=\"_blank\">Cameron Wolfe - Deep Learning Focus - Understanding and Using Supervised Fine-Tuning (SFT) for Language Models</a>\n",
    "    </h6>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ee9871-70a5-40be-882a-2fbca7e9b16d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## ¿Qué es la tokenización?\n",
    "\n",
    "* Los LLMs (y más generalmente cualquier algoritmo de ML) no reconocen texto, sólo números. \n",
    "    * En particular usan IDs para determinar las palabras que tienen de contexto y que tienen que predecir.\n",
    "* La tokenización es el proceso de tomar una secuencia de texto y dividirla en partes más chicas, llamadas tokens.\n",
    "    * Los tokens pueden ser palabras, subpalabras, caracteres, números, símbolos, etc.\n",
    "    * Distintos niveles de granularidad ofrecen diversos pros y contras dependiendo de la tarea.\n",
    "    * Los tokens dependen mucho del idioma con el que se trabajan.\n",
    "* La tokenización sirve para dividir el texto de forma que los modelos puedan procesarlo y tener contexto para reconocer patrones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b547e96-8924-4633-a324-42e224300b59",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Tipos de Tokenización\n",
    "\n",
    "* Dependiendo de la granularidad, hay distintos tipos de tokenización.\n",
    "* La tokenización a nivel palabra crea un token por cada palabra del vocabulario.\n",
    "    * Es útil para idiomas donde las palabras tengan límites claro (e.g., Español, Inglés, etc.).\n",
    "    * Cada forma de una palabra es un token, por lo que el vocabulario puede ser enorme.\n",
    "    * No maneja palabras fuera de vocabulario.\n",
    "* La tokenización a nivel caracter crea un token por cada caracter (incluídos espacios, signos, etc.).\n",
    "    * Útil para idiomas con límites poco claros en las palabras y también para aplicaciones específicas.\n",
    "    * Puede haber mucha pérdida semántica en algunos casos.\n",
    "* La tokenización de subpalabras busca un punto medio entre las tokenizaciones anteriores.\n",
    "    * Se basa en la interpretación semántica de subpalabras de acuerdo al contexto (e.g., chatbot se tokeniza como \"chat\" y \"bot).\n",
    "    * Muy útil para armar palabras con un enfoque \"bottom-up\" (i.e., las palabras se conforman de combinaciones de palabras más chicas).\n",
    "    * Tiene más granularidad y no sufre de problemas de fuera de vocabulario a diferencia de la tokenización a nivel palabra.\n",
    "    * Conservan mayor valor semántico en comparación a la tokenización a nivel caracteres.\n",
    "    * La gran mayoría de los LLMs modernos usan algún algoritmo de tokenización por subpalabras.\n",
    "    * Existen varios algoritmos de tokenización de subpalabras, los más conocidos son [BPE](https://huggingface.co/docs/transformers/en/tokenizer_summary#byte-level-bpe), [WordPiece](https://huggingface.co/docs/transformers/en/tokenizer_summary#wordpiece), [Unigram](https://huggingface.co/docs/transformers/en/tokenizer_summary#unigram) y [SentencePiece](https://huggingface.co/docs/transformers/en/tokenizer_summary#sentencepiece)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6c1b58ea-0a3b-4612-84c9-bcf91dc7ebc8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Visualizando un LLM\n",
    "\n",
    "### Mecanismo de atención\n",
    "\n",
    "<div style=\"text-align:center;\">\n",
    "    <div style=\"display:inline-block;margin-right:20px;\">\n",
    "        <img src=\"./img/AttentionSceneFinal.gif\" style=\"height:30em;width:auto;\"/>\n",
    "    </div>\n",
    "    <h6 style=\"font-style:normal;font-size:1em;margin:5px;\">\n",
    "        Source: <a href=\"https://huggingface.co/learn/agents-course/en/unit1/what-are-llms\" style=\"color:royalblue;\" target=\"_blank\">Hugging Face Agents Course - What are LLMs?</a>\n",
    "    </h6>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fc42c9-20c7-4f84-8673-9dcd9121e4fe",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Predicción de la palabra siguiente\n",
    "\n",
    "<div style=\"text-align:center;\">\n",
    "    <div style=\"display:inline-block;margin-right:20px;\">\n",
    "        <img src=\"./img/DecodingFinal.gif\" style=\"height:30em;width:auto;\"/>\n",
    "    </div>\n",
    "    <h6 style=\"font-style:normal;font-size:1em;margin:5px;\">\n",
    "        Source: <a href=\"https://huggingface.co/learn/agents-course/en/unit1/what-are-llms\" style=\"color:royalblue;\" target=\"_blank\">Hugging Face Agents Course - What are LLMs?</a>\n",
    "    </h6>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677edc0c-c887-4242-bea5-3fa3dbf07e41",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Generación autoregresiva\n",
    "\n",
    "<div style=\"text-align:center;\">\n",
    "    <div style=\"display:inline-block;margin-right:20px;\">\n",
    "        <img src=\"./img/AutoregressionSchema.gif\" style=\"height:30em;width:auto;\"/>\n",
    "    </div>\n",
    "    <h6 style=\"font-style:normal;font-size:1em;margin:5px;\">\n",
    "        Source: <a href=\"https://huggingface.co/learn/agents-course/en/unit1/what-are-llms\" style=\"color:royalblue;\" target=\"_blank\">Hugging Face Agents Course - What are LLMs?</a>\n",
    "    </h6>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947d998e-78ca-46ee-8e42-4db18d50f0d9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## ¿Qué es un embedding?\n",
    "\n",
    "* Los embeddings son representaciones matemáticas de entidades (e.g., tokens, palabras, documentos, registros, etc.).\n",
    "* Se caracterizan por ser una proyección en un espacio vectorial.\n",
    "* Se crean con el objetivo de conservar las similitudes semánticas de las entidades que representan.\n",
    "    * E.g., la idea es que palabras que ocurren en contextos similares tengan vectores similares (medidos por métricas de distancia como la euclídea o similitudes como la coseno).\n",
    "* Las dimensiones de los embeddings representan rasgos latentes (i.e., rasgos que hacen a la similitud semántica de las entidades, pero que no son fácilmente interpretables).\n",
    "    * Si bien pueden crearse embeddings de rasgos explícitos esto suele ser caro (por cuestiones de dispersión, memoria, etc.).\n",
    "* Existen distintos algoritmos para calcular embeddings. En general todos arrancan con embeddings aleatorios y se modifican a medida que se entrenan sobre un corpus.\n",
    "    * [Word2Vec](https://en.wikipedia.org/wiki/Word2vec) es un algoritmo clásico para calcular embeddings de palabras basado en vecindario de palabras.\n",
    "    * Los LLMs hacen cálculo de embeddings internamente en cada capa.\n",
    "* Si quieren una explicación más detallada les sugiero ver mi [charla en Nerdearla 2021](https://www.youtube.com/watch?v=_RvSQsV12fM) o leer el fantástico post de [Jay Alammar](https://jalammar.github.io/illustrated-word2vec/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9c45d7-6889-4818-992b-2bb7d46bceff",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# ¿Qué es un prompt?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35a1fb4-4234-4c70-bdf0-f5688740f8ce",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### La semilla en un modelo de lenguaje\n",
    "\n",
    "* Los modelos de lenguaje son máquinas sin estado.\n",
    "    * No tienen concepto de memoria, estado interno, o estado inicial.\n",
    "* Sirven específicamente para continuar a partir de una entrada inicial.\n",
    "    * Si bien podemos hacer que un modelo \"inicie\" la interacción, esto hace que el modelo inicie de manera completamente aleatoria a generar texto.\n",
    "* Un prompt es la semilla inicial sobre la que un modelo puede construir texto de manera más determinística.\n",
    "    * E.g., un prompt para especificar al LLM que debe traducir al usuario de español a inglés.\n",
    "* Durante la fase de alineamiento los modelos aprenden a completar prompts de formatos específicos."
   ]
  },
  {
   "cell_type": "raw",
   "id": "f5cf1d79-2fd1-4c31-8f60-7533ef57c650",
   "metadata": {
    "editable": true,
    "raw_mimetype": "",
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "\n",
    "Cutting Knowledge Date: December 2023\n",
    "Today Date: 10 Feb 2025\n",
    "\n",
    "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "I need help with my order<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\n",
    "I'd be happy to help. Could you provide your order number?<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "It's ORDER-123<|eot_id|><|start_header_id|>assistant<|end_header_id|>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f691bdfd-1ec9-4e6f-917a-af8462906b21",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## ¿Qué es una ventana de contexto?\n",
    "\n",
    "* Los modelos de lenguaje no tienen la capacidad de sostener un contexto infinito.\n",
    "* Originalmente, los modelos generativos por excelencia, previos al transformer, eran las redes recurrentes.\n",
    "    * La idea de estas redes es que el output de la red servía como input de la misma red en la siguiente fase.\n",
    "    * El problema de las RNNs era su esquema secuencial, cada palabra de la lista debía pasar una tras otra en la red.\n",
    "* El transformer vino a solucionar el problema de la secuencialidad de las RNNs, pero a costa de no poder tener un \"contexto infinito\".\n",
    "* Los transformers pueden procesar paralelamente todas las palabras que tienen de entrada, pero esta lista tiene que ser finita, esto es lo que se conoce como \"ventana de contexto\".\n",
    "    * En realidad si bien teóricamente las RNNs podrían soportar un contexto \"infinito\", en la práctica esto no era practicable, dado que la RNN terminaba perdiendo el contexto de cosas que quedaban \"muy detrás\".\n",
    "* Un transformer no puede leer más palabras que las que su contexto permite.\n",
    "    * También suelen tener problemas de \"interpretación\" mientras más grande sea el contexto.\n",
    "* Muchas veces jugar con los extremos del contexto también juega en contra de los \"saferails\" del transformer en sí."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2b8b40-22ad-4f6b-b8f9-c2579b45dc01",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## ¿Qué significa zero, one y few shot?\n",
    "\n",
    "* Los LLMs son, por sobre todo, *pattern matchers* (i.e., pueden identificar patrones y continuarlos).\n",
    "    * Es por esto que logran seguir una \"conversación\" con cierto tono (ya sea formal, informal, o hacerlos hablar [como piratas](https://simonwillison.net/2023/Apr/14/worst-that-can-happen/#gpt4)).\n",
    "* Dentro del contexto de un LLM, uno puede pedirle que realice alguna tarea.\n",
    "* Zero-shot es el caso cuando no se da ningún ejemplo de como se espera que se realice la tarea o algún ejemplo para dar contexto.\n",
    "    * Esto es muy típico cuando se le pregunta al LLM algún tipo de información que sea de común conocimiento.\n",
    "* One-shot es cuando se le establece 1 solo ejemplo de contexto para la tarea.\n",
    "    * Esto es muy últil cuando se espera que el LLM devuelva algo en algún formato específico (e.g., un JSON con cierto formato).\n",
    "* Few-shot es cuando se le establecen varios ejemplos para el contexto de la tarea.\n",
    "    * Se suele utilizar cuando necesitamos dar más contexto al modelo, ya sea porque la tarea no es tan \"común\" o porque hay más de un ejemplo de como puede realizarse."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d09fb68-48ed-433e-b2d0-88298b233065",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## ¿Qué es Retrieval Augmented Generation (RAG)?\n",
    "\n",
    "* Los LLMs son muy buenos para generar texto, pero son muy malos para ser usados como bases de datos.\n",
    "* Si bien hay ciertos datos que los LLMs pueden dar fehacientemente, sólo son algunos datos que sean muy comunes.\n",
    "    * Esto es a causa de que los LLMs van a tener mejor \"conocimiento\" de datos que aparezcan más seguido en el dataset de entrenamiento.\n",
    "* Sin embargo, si uno le da el contexto al LLM, sí resultan bastante buenos para comunicar datos que sí estén en su contexto.\n",
    "    * Esto es por el mismo mecanismo de atención que los LLMs tienen que hacen hagan más hincapié en lo que está explícito en su contexto por sobre lo que está implícito en sus pesos internos.\n",
    "* El Retrieval Augmented Generation (o RAG) es una técnica para explotar esta última ventaja de los LLMs.\n",
    "    * La idea es poner en el contexto del LLM información fehaciente que haya sido obtenida de algún medio externo sobre el que se tenga confianza (e.g., una base de datos).\n",
    "    * Cualquier medio que tenga los datos correctos sirve para RAG, pero en general se utilizan bases de datos sobre las que se pueda hacer algún tipo de búsqueda semántica (e.g., bases de datos de vectores que tienen embeddings de conceptos).\n",
    "    * La idea es tomar una query de un usuario, buscar los conceptos semánticamente más similares de dicha query en la base de datos (i.e., un *retrieval* o recuperación de los datos) y agregarlos a la ventana de contexto del prompt.\n",
    "    * Finalmente se le indica al LLM que sólo utilice dichos datos como contexto para responder la query del usuario.\n",
    "\n",
    "### Ejemplo de un Prompt de RAG"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6fcfcd7b-15a7-45c2-b1b4-f250ba348ea5",
   "metadata": {
    "editable": true,
    "raw_mimetype": "",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfc0506-7a96-4f77-809c-f89045e4cda4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## ¿Qué es chain-of-thought y qué son los LRMs?\n",
    "\n",
    "* Los LLMs son generadores de texto por sobre todo. Sin embargo, desde el principio se buscó que pudieran razonar.\n",
    "* Unos de los desafíos más grandes de los LLMs se da en problemas lógico matemáticos, cuando se les da un enunciado coloquial, los LLMs tienden a alucinar las respuestas.\n",
    "    * Muchas veces se olvidan detalles, otras veces intentan hacer operaciones matemáticas (e.g., sumas, restas, multiplicación, división, etc.) y los resultados son inexactos (en especial para números más grandes).\n",
    "* Si bien algunos de estos problemas son solucionables mediante el uso de herramientas externas (e.g., indicar al LLM que haga el cálculo con algún programa o similar), el poder de \"razonamiento\" de un LLM sigue siendo interesante y útil.\n",
    "* El estudio de las mecánicas de razonamiento derivó en lo que se llamó [Chain-of-Thought Prompting](https://arxiv.org/abs/2201.11903) donde a un LLM se le dan parámetros para que pueda resolver el problema especificado paso a paso.\n",
    "    * Agregar ejemplos (i.e., few shot) y frases claves como \"let's break down the process into steps\" mostró que los LLMs mejoraban su proceso de razonamiento.\n",
    "* A partir de esa idea se empezaron a idear los _Large Reasoning Models_ (o LRMs), como `o1` de OpenAI, o `DeepSeek-R1`.\n",
    "    * Estos modelos generan \"tokens de razonamiento\" que usan para \"pensar\" y facilitar la resolución de problemas más complejos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a3bced-7f2e-40a0-b353-e2fe05af8297",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# ¿Qué son los Agentes de IA?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2cebb0-cb2a-4854-bfb5-84888b3a9fb4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## LLMs especializados\n",
    "\n",
    "* Ya que los LLMs no tienen concepto de memoria o estado, la idea es utilizar clases y objetos (o más generalmente, tipos abstractos de datos) para especializar corridas sobres los LLMs.\n",
    "* Los agentes buscan encapsular tipos de interacciones con el LLM.\n",
    "    * Un agente suele tener asociado un prompt que los \"especializa\" en alguna tarea en particular.\n",
    "    * La idea es no subespecificar o buscar que los agentes sean para resolución general de problemas, sino para casos específicos.\n",
    "* Un agente interactúa con el modelo enviando un prompt con todas las interacciones acumuladas hasta el momento y procesa lo que el LLM le devuelve.\n",
    "* Un agente además interactúa con el entorno, ya sea ejecutando código, llamando a otros programas, pidiendo más información al usuario, guardando el historial de conversaciones o incluso derivando tareas a otros subagentes.\n",
    "    * El LLM sirve como \"orquestador\" de decisiones y los agentes se encargan de ejecutar dichas decisiones.\n",
    "* Por otra parte, un LLM no tiene poder de interacción por si mismo, depende de un prompt inicial, pero cuando tratamos 1 agente como un usuario, podemos hacer interactuar a múltiples agentes para ejecutar determinadas tareas de manera automática.\n",
    "    * E.g., un agente es el que interactúa con el usuario y se encarga de llamar a agentes más especializados a medida que el usuario hace ciertos pedidos específicos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8711e9-0523-41fa-a9e4-0c1a41d68a2f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## ¿Qué frameworks de agentes existen?\n",
    "\n",
    "* Existen muchos frameworks para programación de aplicaciones de agentes.\n",
    "    * Es un área relativamente reciente y todavía no hay un claro \"ganador\" entre las decenas de candidatos.\n",
    "* Una de los primeros es [LangChain](https://www.langchain.com/) aunque los creadores lo fueron derivando en [LangGraph](https://www.langchain.com/langgraph).\n",
    "    * Otros conocidos son: [LlamaIndex](https://www.llamaindex.ai/), [Semantic Kernel](https://learn.microsoft.com/en-us/semantic-kernel/overview/), [CrewAI](https://www.crewai.com/), [AutoGen](https://microsoft.github.io/autogen/stable//index.html), [Swarm](https://github.com/openai/swarm), [smolagents](https://huggingface.co/docs/smolagents/en/index).\n",
    "    * En lo personal mi favorito es [Pydantic AI](https://ai.pydantic.dev/).\n",
    "* La idea de cualquier framework de agentes es, en el fondo, construir un grafo cuyos nodos son los distintos agentes y las aristas son las interacciones que estos ejecutan.\n",
    "    * Con este concepto en mente es posible incluso armar un [framework de agentes completamente desde cero](https://huggingface.co/learn/agents-course/en/unit1/dummy-agent-library). Los frameworks sólo sirven para ahorrar el boilerplate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2c77b1-8801-4da3-b31a-03248a8540be",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## ¿Qué son tools?\n",
    "\n",
    "* Los agentes pueden interactuar con el entorno, a diferencia de los LLMs.\n",
    "* Una de las principales formas de interacción es acceder a entidades por fuera de lo que el LLM puede acceder (ya que solo es capaz de generar texto y nada más).\n",
    "* Las \"tools\" encapsulan el concepto de lograr que el LLM (mediante los agentes) llame a entidades que ejecutan cosas programáticamente (e.g., hacer un cálculo, llamar a una función, acceder a internet, consultar una base de datos, etc.).\n",
    "    * Por debajo las tools son llamadas mediante el modelo simplemente pasando un string JSON que es interpretado por el agente quien es el que hace la llamada a la herramienta.\n",
    "    * El JSON suele tener el nombre de la tool a llamar y los valores para pasar a sus correspondientes parámetros si los tiene (e.g., si el LLM quiere hacer una búsqueda web el parámetro sería la query).\n",
    "    * Si bien los primeros LLMs eran más bruscos y sólo se esperaba que el modelo generara un JSON válido para llamar a la herramienta correspondiente los nuevos modelos están adaptados con la idea de llamar a una tool en su mismo set de entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbce2a5d-7d99-4978-a0e7-b9d6ad597603",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "<div style=\"text-align:center;\">\n",
    "    <div style=\"display:inline-block;margin-right:20px;\">\n",
    "        <img src=\"./img/weather.jpg\" style=\"height:30em;width:auto;\"/>\n",
    "    </div>\n",
    "    <h6 style=\"font-style:normal;font-size:1em;margin:5px;\">\n",
    "        Source: <a href=\"https://huggingface.co/learn/agents-course/en/unit1/tools\" style=\"color:royalblue;\" target=\"_blank\">Hugging Face Agents Course - What Are Tools?</a>\n",
    "    </h6>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acbe50c-3f0c-4333-8696-17436107c828",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## ¿Qué es Re-Act?\n",
    "\n",
    "* ReAct es una técnica utilizada especialmente en modelos \"razonantes\" que busca armar prompts que busquen razonar (Reasoning) y luego actuar (Act).\n",
    "* El agente sigue un ciclo de Razonamiento, Acción y Observación:\n",
    "    * El razonamiento, ejecutado mediante el LLM, se basa en diagramar las acciones a seguir.\n",
    "    * La acción se ejecuta mediante el uso de alguna tool.\n",
    "    * La observación es mediante la interpretación del resultado de la tool.\n",
    "* El ciclo se repite donde cada etapa alimenta a la siguiente, hasta que el agente decide que se llegó a una respuesta satisfactoria para la query original del usuario."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd770a12-fd41-43cb-83cf-59f51c066b14",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "<div style=\"text-align:center;\">\n",
    "    <div style=\"display:inline-block;margin-right:20px;\">\n",
    "        <img src=\"./img/AgentCycle.gif\" style=\"height:30em;width:auto;\"/>\n",
    "    </div>\n",
    "    <h6 style=\"font-style:normal;font-size:1em;margin:5px;\">\n",
    "        Source: <a href=\"https://huggingface.co/learn/agents-course/en/unit1/agent-steps-and-structure\" style=\"color:royalblue;\" target=\"_blank\">Hugging Face Agents Course - Understanding AI Agents through the Thought-Action-Observation Cycle</a>\n",
    "    </h6>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46ef4c7-3cb4-4590-bf86-ae596c7f1f2d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## ¿Qué es Model-Context Protocol (MCP)?\n",
    "\n",
    "* El problema de acceder a recursos (e.g., bases de datos, ejecución de código, etc.) es que se requiere una API distinta por cada agente/LLM.\n",
    "* Si se tienen múltiples agentes, esto se convierte en un problema de NxM: se necesitan NxM maneras de conectar los N agentes/LLMs con los M recursos disponibles. A medida que la aplicación crece, esto se vuelve más y más complejo.\n",
    "* [Model-Context Protocol (MCP)](https://modelcontextprotocol.io/docs/getting-started/intro) es un estándar abierto diseñado por Anthropic para establecer una conexión común entre agentes en aplicaciones clientes y servidores que ofrecen distintos recuros."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82f7a1b-1552-42d4-b836-3efac5b8e1f8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "<div style=\"text-align:center;\">\n",
    "    <div style=\"display:inline-block;margin-right:20px;\">\n",
    "        <img src=\"./img/mcp.png\" style=\"height:30em;width:auto;\"/>\n",
    "    </div>\n",
    "    <h6 style=\"font-style:normal;font-size:1em;margin:5px;\">\n",
    "        Source: <a href=\"https://modelcontextprotocol.io/docs/getting-started/intro\" style=\"color:royalblue;\" target=\"_blank\">Model Context Protocol Documentation</a>\n",
    "    </h6>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3743d577-f0ab-4b7e-ba78-9f031f3d7cfb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Ejemplo: Weather Agent with Pydantic AI (1/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f16db34-4ba2-479d-a83a-81c970b772b7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "from pydantic import BaseModel\n",
    "from pydantic_ai import Agent, RunContext\n",
    "from rich.pretty import pprint\n",
    "\n",
    "os.environ[\"OLLAMA_BASE_URL\"] = \"http://localhost:11434/v1\"\n",
    "\n",
    "\n",
    "class CityWeather(BaseModel):\n",
    "    city: str\n",
    "    country: str\n",
    "    temperature: str\n",
    "    humidity: str\n",
    "    wind_speed: str\n",
    "    wind_direction: str\n",
    "\n",
    "\n",
    "agent = Agent(\n",
    "    'ollama:qwen3:0.6b',\n",
    "    system_prompt=\"If the user asks for the weather conditions on a city, use the `get_weather` tool to retrieve the current weather conditions and write a summary based on the results\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bae51bb-8ef5-4a3c-a02a-c524fd166223",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Ejemplo: Weather Agent with Pydantic AI (2/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cca3005-c5ed-4345-8f08-47d52a01ad27",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@agent.tool\n",
    "def get_weather(ctx: RunContext[str], city: str, country: str) -> CityWeather | str:\n",
    "    coordinates = requests.get(\n",
    "        url=\"https://nominatim.openstreetmap.org/search\",\n",
    "        params={\n",
    "            \"city\": city,\n",
    "            \"country\": country,\n",
    "            \"format\": \"jsonv2\",\n",
    "        },\n",
    "        headers = {\n",
    "            \"User-Agent\": \"PydanticAI Weather Forecast Test Agent\"\n",
    "        }\n",
    "    ).json()\n",
    "\n",
    "    if not coordinates:\n",
    "        return f\"The city {city} in country {country}, doesn't exists, please provide a valid city and country\"\n",
    "\n",
    "    latitude = round(float(coordinates[0][\"lat\"]), 2)\n",
    "    longitude = round(float(coordinates[0][\"lon\"]), 2)\n",
    "    \n",
    "    weather = requests.get(\n",
    "        url=\"https://api.open-meteo.com/v1/forecast\",\n",
    "        params={\n",
    "            \"latitude\": latitude,\n",
    "            \"longitude\": longitude,\n",
    "            \"current\": \"temperature_2m,relative_humidity_2m,wind_speed_10m,wind_direction_10m\",\n",
    "        }\n",
    "    ).json()\n",
    "    return CityWeather(\n",
    "        city=city,\n",
    "        country=country,\n",
    "        temperature=f\"{weather['current']['temperature_2m']} {weather['current_units']['temperature_2m']}\",\n",
    "        humidity=f\"{weather['current']['relative_humidity_2m']} {weather['current_units']['relative_humidity_2m']}\",\n",
    "        wind_speed=f\"{weather['current']['wind_speed_10m']} {weather['current_units']['wind_speed_10m']}\",\n",
    "        wind_direction=f\"{weather['current']['wind_direction_10m']} {weather['current_units']['wind_direction_10m']}\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb93a52-0433-4557-bf18-e01cc292854d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Ejemplo: Weather Agent with Pydantic AI (3/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec39f28-ad11-4961-adbc-b5e05b0efda3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "result = await agent.run(\n",
    "    'Can you give me the weather forecasting for the city of Buenos Aires, Argentina?'\n",
    ")\n",
    "print(result.output)\n",
    "\n",
    "for message in result.all_messages():\n",
    "    pprint(message.parts)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  },
  "rise": {
   "scroll": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
